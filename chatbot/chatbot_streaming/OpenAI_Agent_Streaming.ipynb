{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXkbiSEoYOqRz+rKq2Q9iQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nwvx3KQYX-d",
        "outputId": "324d7769-91bd-42e9-df4a-7ffa75f4f4d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "GDty8WbhYkXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel\n",
        "from agents.run import RunConfig\n",
        "from google.colab import userdata\n",
        "\n",
        "from agents import (\n",
        "    Agent,\n",
        "    Runner,\n",
        "    set_default_openai_api,\n",
        "    set_default_openai_client,\n",
        "    set_tracing_disabled,\n",
        ")\n",
        "\n",
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "\n",
        "# Check if the API key is present; if not, raise an error\n",
        "if not gemini_api_key:\n",
        "    raise ValueError(\"GEMINI_API_KEY is not set. Please ensure it is defined in your .env file.\")\n",
        "\n",
        "#Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=external_client\n",
        ")\n",
        "\n",
        "set_default_openai_client(client=external_client, use_for_tracing=False)\n",
        "set_default_openai_api(\"chat_completions\")\n",
        "set_tracing_disabled(disabled=True)"
      ],
      "metadata": {
        "id": "iR-o29oTYnNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Streaming Text Code"
      ],
      "metadata": {
        "id": "0I3vFpxLZ7NH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "from openai.types.responses import ResponseTextDeltaEvent\n",
        "\n",
        "from agents import Agent, Runner\n",
        "\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Joker\",\n",
        "        instructions=\"You are a helpful assistant.\",\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    result = Runner.run_streamed(agent, input=\"Please tell me 5 jokes.\")\n",
        "    async for event in result.stream_events():\n",
        "        if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
        "            print(event.data.delta, end=\"\", flush=True)\n",
        "\n",
        "\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L0VIO7sZgUj",
        "outputId": "88eaeffb-f47a-400c-b01b-6e1f20eced19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alright, here are 5 jokes for you:\n",
            "\n",
            "1.  Why don't scientists trust atoms?\n",
            "    Because they make up everything!\n",
            "\n",
            "2.  Parallel lines have so much in common.\n",
            "    It's a shame they'll never meet.\n",
            "\n",
            "3.  Why did the scarecrow win an award?\n",
            "    Because he was outstanding in his field!\n",
            "\n",
            "4.  What do you call a lazy kangaroo?\n",
            "    Pouch potato!\n",
            "\n",
            "5.  Why did the bicycle fall over?\n",
            "    Because it was two tired!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import random\n",
        "\n",
        "from agents import Agent, Runner, ItemHelpers, function_tool\n",
        "\n",
        "@function_tool\n",
        "def how_many_jokes()->int:\n",
        "  return random.randint(1, 10)\n",
        "\n",
        "async def main():\n",
        "  agent = Agent(\n",
        "      name=\"Joker\",\n",
        "      instructions=\"first call the `how_many_jokes` tool, then tell that many jokes.\",\n",
        "      model=model,\n",
        "      tools=[how_many_jokes]\n",
        "  )\n",
        "\n",
        "  result = Runner.run_streamed(\n",
        "      agent,\n",
        "      input=\"Hello\"\n",
        "  )\n",
        "\n",
        "  print(\"====Run Starting====\")\n",
        "  async for event in result.stream_events():\n",
        "    # we'll ignore the raw responses  event deltas\n",
        "    if event.type == \"raw_response_event\":\n",
        "      continue\n",
        "    elif event.type == \"agent_updated_stream_event\":\n",
        "      print(f\"Agent updated stream event: {event.new_agent.name}\")\n",
        "      continue\n",
        "    elif event.type == \"run_item_stream_event\":\n",
        "      if event.item.type == \"tool_call_item\":\n",
        "        print(\"---Tool was called---\")\n",
        "      elif event.item.type == \"tool_call_output_item\":\n",
        "        print(f\"---Tool Output : {event.item.output}\")\n",
        "      elif event.item.type == \"message_output_item\":\n",
        "        print(f\"Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n",
        "      else:\n",
        "        pass # Ignore others event\n",
        "\n",
        "try:\n",
        "  asyncio.run(main())\n",
        "except:\n",
        "  pass\n",
        "print(\"===Run complete===\")"
      ],
      "metadata": {
        "id": "NSWm-NAqcZvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f158a90-2157-4cd7-b5e5-d8b7de99fcf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====Run Starting====\n",
            "Agent updated stream event: Joker\n",
            "---Tool was called---\n",
            "---Tool Output : 7\n",
            "Message output:\n",
            " I will tell you 7 jokes.\n",
            "\n",
            "Why don't scientists trust atoms?\n",
            "Because they make up everything!\n",
            "\n",
            "What do you call a lazy kangaroo?\n",
            "Pouch potato!\n",
            "\n",
            "Why did the bicycle fall over?\n",
            "Because it was two tired!\n",
            "\n",
            "Why did the scarecrow win an award?\n",
            "Because he was outstanding in his field!\n",
            "\n",
            "What do you call a fish with no eyes?\n",
            "Fsh!\n",
            "\n",
            "Why did the teddy bear say no to dessert?\n",
            "Because she was stuffed!\n",
            "\n",
            "What musical instrument is found in the bathroom?\n",
            "A tuba toothpaste.\n",
            "\n",
            "===Run complete===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6XaGgSCFG39R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}